"""
News Collector Lambda Handler

Entry point for collecting news articles from NewsAPI.
Independent from review collection - separate Lambda function.
"""

import os
import json
import logging
import sys
from typing import Dict, Any

# Add shared layer to path
sys.path.insert(0, '/opt/python')

from newsapi_client import NewsAPIClient
from news_repository import NewsArticleRepository
from collect_news_use_case import CollectNewsUseCase
from request_schema import (
    CollectNewsRequest,
    CollectNewsResponse,
    parse_lambda_event,
    format_lambda_response
)

# Import from Lambda Layer (shared infrastructure)
from infrastructure.clients.secrets_client import SecretsClient


# Configure logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)


def lambda_handler(event, context):
    """
    ğŸ¯ Lambda handler for news collection from NewsAPI.
    
    Supports 3 invocation methods:
    
    1ï¸âƒ£ API Gateway (HTTP POST)
    ---------------------------
    POST /collect-news
    {
        "brand": "Tesla",
        "limit": 50,
        "search_type": "everything",
        "from_date": "2025-10-01",
        "language": "en",
        "job_id": "job_20251004_abc123" (optional)
    }
    
    2ï¸âƒ£ Direct Lambda Invoke
    ------------------------
    aws lambda invoke --function-name news-collector-lambda \
      --payload '{"brand":"Tesla","limit":50}'
    
    3ï¸âƒ£ Step Functions Invoke (NEW)
    -------------------------------
    Called from Step Functions with job_id for orchestration
    
    Args:
        event: Event data (format depends on invocation method)
        context: Lambda context object
        
    Returns:
        Response with collection statistics
    """
    logger.info("=" * 60)
    logger.info("ğŸ—ï¸  News Collector Lambda Started")
    logger.info("=" * 60)
    logger.info(f"Event: {json.dumps(event, default=str)}")
    
    try:
        # Extract job_id if provided (for Step Functions orchestration)
        job_id = event.get('job_id') if isinstance(event, dict) else None
        if job_id:
            logger.info(f"ğŸ”– Job ID: {job_id}")
        
        # ğŸ” Parse and validate request
        request = parse_lambda_event(event)
        logger.info(f"âœ… Parsed request: {request.to_dict()}")
        
        # ğŸš€ Execute collection
        stats = _collect_news(request, job_id=job_id)
        
        # ğŸ“Š Format success response
        response_data = {
            'success': True,
            'message': 'News articles collected successfully',
            'statistics': stats,
            'request': request.to_dict()
        }
        
        # Add job_id to response if provided
        if job_id:
            response_data['job_id'] = job_id
        
        logger.info("=" * 60)
        logger.info("âœ… Lambda execution completed successfully")
        logger.info("=" * 60)
        
        return format_lambda_response(200, response_data)
        
    except ValueError as e:
        logger.error(f"âŒ Validation error: {e}")
        error_response = {
            'success': False,
            'error': 'ValidationError',
            'message': str(e),
            'request': event if isinstance(event, dict) else {}
        }
        return format_lambda_response(400, error_response)
        
    except Exception as e:
        logger.error(f"âŒ Execution failed: {e}", exc_info=True)
        error_response = {
            'success': False,
            'error': 'InternalServerError',
            'message': str(e),
            'request': event if isinstance(event, dict) else {}
        }
        return format_lambda_response(500, error_response)


def _collect_news(request: CollectNewsRequest, job_id: str = None) -> Dict[str, Any]:
    """
    Execute news collection workflow.
    
    Args:
        request: Validated CollectNewsRequest
        job_id: Optional job identifier for grouping news articles
        
    Returns:
        Statistics dictionary
    """
    logger.info(f"ğŸ¯ Collecting news for brand: {request.brand}")
    logger.info(f"   Search type: {request.search_type}")
    logger.info(f"   Limit: {request.limit}")
    if job_id:
        logger.info(f"   Job ID: {job_id}")
    
    # Get NewsAPI credentials from Secrets Manager
    logger.info("ğŸ” Retrieving NewsAPI credentials...")
    secrets_client = SecretsClient()
    newsapi_key = secrets_client.get_newsapi_key()
    
    if not newsapi_key:
        raise ValueError("NewsAPI key not found in Secrets Manager")
    
    logger.info("âœ… Retrieved NewsAPI credentials")
    
    # Initialize NewsAPI client
    api_client = NewsAPIClient(newsapi_key)
    logger.info("âœ… Initialized NewsAPI client")
    
    # Initialize repository with job_id support
    repository = NewsArticleRepository(job_id=job_id)
    logger.info("âœ… Initialized NewsArticle repository")
    
    # Execute use case
    use_case = CollectNewsUseCase(api_client, repository)
    
    logger.info("ğŸš€ Starting collection workflow...")
    stats = use_case.execute(
        brand=request.brand,
        limit=request.limit,
        search_type=request.search_type,
        from_date=request.from_date,
        to_date=request.to_date,
        language=request.language,
        country=request.country,
        category=request.category,
        sources=request.sources,
        search_in=request.search_in
    )
    
    logger.info(f"ğŸ“Š Collection statistics: {stats}")
    
    return stats

